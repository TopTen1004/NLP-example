{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac7783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8b3e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d2c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_features():\n",
    "    all_features = pd.DataFrame()\n",
    "    all_features = pd.read_csv(r'Dataset/Features.csv')\n",
    "    features = all_features.RepText\n",
    "    features = features.str.lower()    \n",
    "    features.to_csv('selected_features.csv')\n",
    "def preprocessing_labels():\n",
    "    all_labels = pd.read_csv(r'Dataset/Labels.csv')\n",
    "    # pivoting target\n",
    "    new_labels = all_labels.pivot(index='RepID',columns='ICDCODE', values='ICDCODE')\n",
    "    new_labels =  new_labels.fillna(0)\n",
    "    new_labels[new_labels != 0 ] = 1\n",
    "    new_labels.to_csv('selected_labels.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142184a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_from_csv_():\n",
    "    features = pd.read_csv(r'selected_features.csv')\n",
    "    features = features['RepText']\n",
    "    return features\n",
    "def labels_from_csv():\n",
    "    labels = pd.read_csv(r'selected_labels.csv')\n",
    "    labels =labels.drop(['RepID'], axis=1)\n",
    "    data_labels = labels[:59000]\n",
    "    return data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a13d0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the tokenizer to features\n",
    "def tokenize_features(features):\n",
    "    tokenizer = Tokenizer()\n",
    "    def max_caption_length(features):\n",
    "        return max(len(feature.split()) for feature in features)\n",
    "    max_length = max_caption_length(features)\n",
    "    tokenizer.fit_on_texts(features)\n",
    "    # save tokenized features\n",
    "    X = list()\n",
    "    new_X = pd.DataFrame()\n",
    "    for i in range(59000):    \n",
    "        # i = i + 50000\n",
    "        word_idxs = tokenizer.texts_to_sequences([features[i]])[0]\n",
    "        text = pad_sequences([word_idxs], maxlen=max_length, padding='post')[0]                                \n",
    "        X.append(text)\n",
    "    new_X = pd.DataFrame(X)\n",
    "    new_X.to_csv('token_features4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea1e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_features_from_csv():    \n",
    "    features1 = pd.read_csv(r'token_features1.csv')\n",
    "    features2 = pd.read_csv(r'token_features2.csv')\n",
    "    features3 = pd.read_csv(r'token_features3.csv')\n",
    "    arr_features1 = features1.to_numpy()\n",
    "    arr_features2 = features2.to_numpy()\n",
    "    arr_features3 = features3.to_numpy()\n",
    "    arr = np.concatenate([arr_features1, arr_features2, arr_features3])\n",
    "    token_features = pd.DataFrame(arr)\n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1c0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_features = token_features_from_csv()\n",
    "data_labels = labels_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d38e6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_train_test_data(token_features, data_labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(token_features, data_labels, test_size=0.2, random_state=42, shuffle = True, stratify = None)\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    xtrain = X_train.to_numpy()\n",
    "    ytrain = y_train.to_numpy()\n",
    "    xtest = X_test.to_numpy()\n",
    "    ytest = y_test.to_numpy()\n",
    "    xtrain = np.expand_dims(xtrain, axis=1)\n",
    "    xtest = np.expand_dims(xtest, axis=1)\n",
    "    print('xtrain=', xtrain.shape,'   xtest=', xtest.shape)\n",
    "    return xtrain, xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbabd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_torch_data(xtrain, xtest, ytrain, ytest):\n",
    "    batch_size = 3\n",
    "    X_train_ts = torch.tensor(xtrain, dtype=torch.float32)\n",
    "    y_train_ts = torch.tensor(ytrain, dtype=torch.float32)\n",
    "    X_test_ts = torch.tensor(xtest, dtype=torch.float32)\n",
    "    y_test_ts = torch.tensor(ytest, dtype=torch.float32)\n",
    "\n",
    "    dataset_train = TensorDataset(X_train_ts, y_train_ts)\n",
    "    dataset_val = TensorDataset(X_test_ts, y_test_ts)\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, \n",
    "                                sampler=RandomSampler(dataset_train), \n",
    "                                batch_size=batch_size)\n",
    "\n",
    "    dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)\n",
    "    return dataloader_train, dataloader_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7865a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47200, 3640) (11800, 3640) (47200, 1416) (11800, 1416)\n",
      "xtrain= (47200, 1, 3640)    xtest= (11800, 1, 3640)\n"
     ]
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest =  preprocessing_train_test_data(token_features, data_labels)\n",
    "dataloader_train, dataloader_validation = preprocessing_torch_data(xtrain, xtest, ytrain, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8d0a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model building\n",
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self, num_targetlabel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module('conv_1', nn.Conv1d(in_channels=1, out_channels=3640, kernel_size=5))\n",
    "        self.conv.add_module('pool_1', nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module('relu_1', nn.ReLU())\n",
    "        self.conv.add_module('conv_2', nn.Conv1d(in_channels=3640, out_channels=128, kernel_size=2))\n",
    "        self.conv.add_module('pool_2', nn.MaxPool1d(kernel_size=2))\n",
    "        self.conv.add_module('relu_2', nn.ReLU())\n",
    "\n",
    "        self.dense = nn.Sequential()\n",
    "        self.dense.add_module('flatten', nn.Flatten())\n",
    "        self.dense.add_module('linear', nn.Linear(116224, num_targetlabel))\n",
    "        self.dense.add_module('sigmoid', nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        y = self.dense(x)\n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc36c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_Net(\n",
       "  (conv): Sequential(\n",
       "    (conv_1): Conv1d(1, 3640, kernel_size=(5,), stride=(1,))\n",
       "    (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (relu_1): ReLU()\n",
       "    (conv_2): Conv1d(3640, 128, kernel_size=(2,), stride=(1,))\n",
       "    (pool_2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (relu_2): ReLU()\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=116224, out_features=1416, bias=True)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_Net(1416)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bec3f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f781f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    if type(y_pred)==list:\n",
    "        y_pred = np.array(y_pred)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    if type(y_true)==list:\n",
    "        y_true = np.array(y_true)\n",
    "    acc = (y_pred==y_true).mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "def evaluate_valid(model, progress_bar, device):\n",
    "    global cfg\n",
    "    model.eval()\n",
    "    \n",
    "    y_true_lst, y_pred_lst = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            y_pred = model(batch[0])\n",
    "            y_pred_lst += list(y_pred.detach().cpu().numpy())\n",
    "            y_true_lst += list(batch[1].detach().cpu().numpy())            \n",
    "            \n",
    "    model.train() \n",
    "    acc = accuracy(y_pred_lst, y_true_lst)\n",
    "\n",
    "    return acc\n",
    "    \n",
    "def train(model, progress_bar, optimizer, loss_func, device):\n",
    "    # global cfg, global_step_num\n",
    "    model.train()  \n",
    "    \n",
    "    y_true_lst, y_pred_lst = [], []    \n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # global_step_num += 1\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        # optimizer.zero_grad()        \n",
    "\n",
    "        y_pred = model(batch[0])\n",
    "        train_loss = loss_func(y_pred, batch[1])\n",
    "\n",
    "        y_pred_lst += list(y_pred.detach().cpu().numpy())\n",
    "        y_true_lst += list(batch[1].detach().cpu().numpy())\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(train_loss.item()/len(batch))})\n",
    "        \n",
    "    # print('in train(), len(dl_train): ', len(dl_train))\n",
    "        \n",
    "    acc = accuracy(y_pred_lst, y_true_lst)\n",
    "    return acc\n",
    "\n",
    "print('ok')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d29b6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_train, dataloader_validation):\n",
    "    loss_func = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "    epochs =3\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "        \n",
    "        progress_bar_train = tqdm(dataloader_train, desc='train Epoch {:1d}'.format(epoch), leave=False, disable=False)    \n",
    "        train_acc = train(model=model, progress_bar=progress_bar_train, optimizer=optimizer, loss_func=loss_func, device=device)    \n",
    "\n",
    "        progress_bar_valid = tqdm(dataloader_validation, desc='valid Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "        valid_acc = evaluate_valid(model=model, progress_bar=progress_bar_valid, device=device)\n",
    "        print('valid accuracy:', valid_acc)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ecde147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2241a008af8456c8190185fd19aca50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d31614856c847708d9bc47f12308f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train Epoch 1:   0%|          | 0/15734 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, dataloader_train, dataloader_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0173335",
   "metadata": {},
   "source": [
    "## f1_score calculation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4643c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82c747d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60767123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988debbef554438795e7a160c92632c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xtest1 = np.expand_dims(xtrain, axis=1)\n",
    "# xtest1 = torch.tensor(xtest1, dtype=torch.float32)\n",
    "y_predarr_for_test = []\n",
    "pre_i = 0\n",
    "for i in tqdm(range(100)):    \n",
    "    i = (i+1)*10\n",
    "    y_pred_for_test = model(torch.tensor(xtrain[pre_i:i], dtype=torch.float32))\n",
    "    y_predarr_for_test.append(y_pred_for_test.detach().numpy())\n",
    "    pre_i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72db264d25f4805bd64a1e4df5a3c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1416)\n"
     ]
    }
   ],
   "source": [
    "y_pred_for_testing = y_predarr_for_test[0]\n",
    "for i in tqdm(range(99)):\n",
    "    i += 1\n",
    "    # print(y_predarr_for_test[i].shape)    \n",
    "    y_pred_for_testing = np.concatenate((y_pred_for_testing, y_predarr_for_test[i]), axis=0)\n",
    "print(y_pred_for_testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9ae84a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation_f1(y_pred, y_true):\n",
    "    y_pred_list = y_pred\n",
    "    y_pred_list[y_pred_list >= 0.5] = 1\n",
    "    y_pred_list[y_pred_list < 0.5] = 0\n",
    "    # export = pd.DataFrame(y_pred_list)\n",
    "    # export.to_csv('export.csv')    \n",
    "    y_true_list = y_true[:1000]        \n",
    "    cm = f1_score(y_true = y_true_list, y_pred=y_pred_list, average='micro', zero_division=1)\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "025c329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04024356883048461\n"
     ]
    }
   ],
   "source": [
    "calculation_f1(y_pred_for_testing, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66c1c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "y_true2 = np.array([[1, 0.3, 0.9, 0], [1,1,0,0], [1,1,1,1]])\n",
    "y_pred2 = np.array([[1,0,0,0], [1,1,1,0], [1,1,1,1]])\n",
    "print(y_true2.shape)\n",
    "print(y_pred2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "244f340c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8baa0335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a44a7dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab42430a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100)\n",
      "tensor([[0.4290, 0.3116, 0.0096, 0.0464, 0.0141, 0.1665, 0.0182, 0.0098, 0.0033,\n",
      "         0.0073, 0.0017, 0.0027, 0.0010]], grad_fn=<SigmoidBackward0>)\n",
      "{'Bug': 0, 'Improvement': 1, 'Task': 2, 'New Feature': 3, 'Documentation': 4, 'Sub-task': 5, 'Test': 6, 'Question': 7, 'Wish': 8, 'Umbrella': 9, 'Dependency upgrade': 10, 'Story': 11, 'Brainstorming': 12}\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "x_series = pd.Series(test_issue)\n",
    "test_series = preprocessing_featrue(x_series)\n",
    "x = torch.tensor(test_series, dtype=torch.float32)\n",
    "y = model(x)\n",
    "print(y)\n",
    "print(label_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
